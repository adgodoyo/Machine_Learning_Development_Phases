{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch es una técnica exhaustiva para la búsqueda de hiperparámetros en la cual se prueban todas las combinaciones posibles de los valores que has definido para cada hiperparámetro. Esto garantiza encontrar la mejor combinación, pero puede ser costoso en términos computacionales cuando hay muchas combinaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de Iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a jugar con dos modelos\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los hiperparámetros para GridSearch posibles para cada modelo\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Mejores parámetros para RandomForest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Mejores parámetros para SVM: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Realizar GridSearch para cada modelo\n",
    "best_params_grid = {}\n",
    "for model_name in models:\n",
    "    grid_search = GridSearchCV(estimator=models[model_name], param_grid=param_grids[model_name], cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params_grid[model_name] = grid_search.best_params_\n",
    "    print(f\"Mejores parámetros para {model_name}: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Argumentos de gridsearch**\n",
    "\n",
    "`n_jobs`\n",
    "\n",
    "El parámetro n_jobs especifica el número de trabajos (procesos) que se utilizarán en paralelo para realizar la búsqueda. Sus posibles valores son:\n",
    "\n",
    "`n_jobs=1`: Usa un solo núcleo de CPU para realizar la búsqueda (sin paralelismo).\n",
    "`n_jobs=-1`: Usa todos los núcleos de CPU disponibles en el sistema para realizar la búsqueda en paralelo, lo que puede acelerar significativamente el proceso de búsqueda, especialmente en conjuntos de datos grandes o con una gran cantidad de combinaciones de hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`verbose`\n",
    "\n",
    "El parámetro verbose controla el nivel de detalle que se muestra en la salida estándar (consola) durante la ejecución de GridSearchCV. Los posibles valores son:\n",
    "\n",
    "`verbose=0`: Sin salida (silencioso).\n",
    "\n",
    "`verbose=1`: Muestra una cantidad mínima de información (generalmente el inicio y el final de la búsqueda).\n",
    "\n",
    "`verbose=2`: Muestra información más detallada, incluyendo el progreso de cada iteración en la búsqueda de hiperparámetros. Esto es útil para entender cómo progresa la búsqueda, especialmente cuando se trata de un proceso que puede tomar mucho tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión final para RandomForest: 1.0\n",
      "Precisión final para SVM: 1.0\n"
     ]
    }
   ],
   "source": [
    "final_models = {\n",
    "    'RandomForest': RandomForestClassifier(**best_params_grid['RandomForest']),\n",
    "    'SVM': SVC(**best_params_grid['SVM'])\n",
    "}\n",
    "\n",
    "for model_name in final_models:\n",
    "    final_models[model_name].fit(X_train, y_train)\n",
    "    y_pred = final_models[model_name].predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precisión final para {model_name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomSearch es una técnica de optimización de hiperparámetros que selecciona aleatoriamente combinaciones de valores dentro de un rango definido. A diferencia de GridSearch, no evalúa todas las combinaciones posibles, lo que lo hace más eficiente, aunque no garantiza encontrar la combinación óptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Mejores parámetros para RandomForest con RandomizedSearch: {'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 4}\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Mejores parámetros para SVM con RandomizedSearch: {'kernel': 'rbf', 'gamma': 0.012742749857031334, 'C': 78.47599703514607}\n",
      "Precisión final para RandomForest: 1.0\n",
      "Precisión final para SVM: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset de Iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir los modelos a usar\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Definir los hiperparámetros para RandomizedSearch\n",
    "param_distributions = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': np.arange(10, 200, 10),\n",
    "        'max_depth': np.arange(1, 20, 1),\n",
    "        'min_samples_split': np.arange(2, 10, 1),\n",
    "        'min_samples_leaf': np.arange(1, 10, 1)\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'gamma': np.logspace(-4, 4, 20),\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Realizar RandomizedSearch para cada modelo\n",
    "best_params_random = {}\n",
    "for model_name in models:\n",
    "    random_search = RandomizedSearchCV(estimator=models[model_name], param_distributions=param_distributions[model_name], n_iter=50, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_params_random[model_name] = random_search.best_params_\n",
    "    print(f\"Mejores parámetros para {model_name} con RandomizedSearch: {random_search.best_params_}\")\n",
    "\n",
    "# Evaluar el rendimiento de los modelos ajustados\n",
    "final_models = {\n",
    "    'RandomForest': RandomForestClassifier(**best_params_random['RandomForest']),\n",
    "    'SVM': SVC(**best_params_random['SVM'])\n",
    "}\n",
    "\n",
    "for model_name in final_models:\n",
    "    final_models[model_name].fit(X_train, y_train)\n",
    "    y_pred = final_models[model_name].predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precisión final para {model_name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinando Grid Search y Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, se utiliza RandomSearch primero para explorar rápidamente el espacio de hiperparámetros y encontrar \"regiones\" donde los jiperparámetros tienen un buen desempeño. Luego, se aplica GridSearch dentro de esa región más prometedora para afinar y encontrar la mejor combinación de hiperparámetros con mayor precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 parámetros para RandomForest con RandomizedSearch:\n",
      "1: {'n_estimators': 40, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_depth': 3}\n",
      "2: {'n_estimators': 140, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_depth': 9}\n",
      "3: {'n_estimators': 110, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_depth': 4}\n",
      "4: {'n_estimators': 10, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 7}\n",
      "5: {'n_estimators': 190, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_depth': 18}\n",
      "Top 5 parámetros para SVM con RandomizedSearch:\n",
      "1: {'kernel': 'rbf', 'gamma': 0.012742749857031334, 'C': 78.47599703514607}\n",
      "2: {'kernel': 'sigmoid', 'gamma': 0.0001, 'C': 10000.0}\n",
      "3: {'kernel': 'linear', 'gamma': 0.03359818286283781, 'C': 4.281332398719396}\n",
      "4: {'kernel': 'rbf', 'gamma': 0.00026366508987303583, 'C': 10000.0}\n",
      "5: {'kernel': 'linear', 'gamma': 0.08858667904100823, 'C': 10000.0}\n",
      "Mejores parámetros para RandomForest con GridSearch afinado: {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 5, 'n_estimators': 30}\n",
      "Mejores parámetros para SVM con GridSearch afinado: {'C': 78.47599703514607, 'gamma': 0.012742749857031334, 'kernel': 'rbf'}\n",
      "Precisión final para RandomForest: 1.0\n",
      "Precisión final para SVM: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset de Iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir los modelos a usar\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Definir los hiperparámetros para RandomSearch y GridSearch\n",
    "param_distributions = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': np.arange(10, 200, 10),\n",
    "        'max_depth': np.arange(1, 20, 1),\n",
    "        'min_samples_split': np.arange(2, 10, 1),\n",
    "        'min_samples_leaf': np.arange(1, 10, 1)\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'gamma': np.logspace(-4, 4, 20),\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Realizar RandomizedSearch para encontrar áreas prometedoras de hiperparámetros\n",
    "random_search_results = {}\n",
    "top_5_params = {}\n",
    "for model_name in models:\n",
    "    random_search = RandomizedSearchCV(models[model_name], param_distributions[model_name], n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    random_search_results[model_name] = random_search.cv_results_\n",
    "    top_5_indices = np.argsort(random_search.cv_results_['rank_test_score'])[:5]\n",
    "    top_5_params[model_name] = [random_search.cv_results_['params'][i] for i in top_5_indices]\n",
    "    print(f\"Top 5 parámetros para {model_name} con RandomizedSearch:\")\n",
    "    for i, params in enumerate(top_5_params[model_name], 1):\n",
    "        print(f\"{i}: {params}\")\n",
    "\n",
    "# Afinar con GridSearch en las áreas prometedoras encontradas por RandomizedSearch\n",
    "final_params = {}\n",
    "for model_name in models:\n",
    "    grid_search_results = []\n",
    "    for params in top_5_params[model_name]:\n",
    "        # Crear un espacio de búsqueda reducido alrededor de los mejores parámetros\n",
    "        if model_name == 'RandomForest':\n",
    "            param_grid = {\n",
    "                'n_estimators': range(max(10, params['n_estimators'] - 20), min(200, params['n_estimators'] + 20), 10),\n",
    "                'max_depth': range(max(1, params['max_depth'] - 2), min(20, params['max_depth'] + 2), 1),\n",
    "                'min_samples_split': [params['min_samples_split']],\n",
    "                'min_samples_leaf': [params['min_samples_leaf']]\n",
    "            }\n",
    "        elif model_name == 'SVM':\n",
    "            param_grid = {\n",
    "                'C': np.logspace(np.log10(params['C']) - 1, np.log10(params['C']) + 1, 5),\n",
    "                'gamma': np.logspace(np.log10(params['gamma']) - 1, np.log10(params['gamma']) + 1, 5),\n",
    "                'kernel': [params['kernel']]\n",
    "            }\n",
    "        \n",
    "        grid_search = GridSearchCV(models[model_name], param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        grid_search_results.append((grid_search.best_params_, grid_search.best_score_))\n",
    "    \n",
    "    # Seleccionar los mejores parámetros entre las búsquedas de GridSearch\n",
    "    best_params = sorted(grid_search_results, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    final_params[model_name] = best_params\n",
    "    print(f\"Mejores parámetros para {model_name} con GridSearch afinado: {best_params}\")\n",
    "\n",
    "# Evaluar el rendimiento final de los modelos ajustados\n",
    "final_models = {\n",
    "    'RandomForest': RandomForestClassifier(**final_params['RandomForest']),\n",
    "    'SVM': SVC(**final_params['SVM'])\n",
    "}\n",
    "\n",
    "for model_name in final_models:\n",
    "    final_models[model_name].fit(X_train, y_train)\n",
    "    y_pred = final_models[model_name].predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precisión final para {model_name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daniel Godoy Ortiz \n",
    "[LinkedIn Profile](https://www.linkedin.com/in/adgodoyo/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
